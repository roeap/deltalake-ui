{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delta\n",
    "import delta.pip_utils\n",
    "import delta.tables\n",
    "import pyspark\n",
    "import pyarrow as pa\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "def get_spark():\n",
    "    builder = (\n",
    "        pyspark.sql.SparkSession.builder.appName(\"lakehouse\")\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\n",
    "            \"spark.sql.catalog.spark_catalog\",\n",
    "            \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "        )\n",
    "    )\n",
    "    return delta.pip_utils.configure_spark_with_delta_pip(builder).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime: timestamp[us, tz=UTC]\n",
      "datetime: timestamp[us]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from deltalake import DeltaTable\n",
    "\n",
    "df = pl.select(pl.datetime(2010, 1, 1, time_unit=\"us\", time_zone=\"UTC\"))\n",
    "\n",
    "print(df.to_arrow().schema)\n",
    "\n",
    "df.write_delta('test')\n",
    "df.write_parquet(\"test.parquet\")\n",
    "\n",
    "dt = DeltaTable('test')\n",
    "\n",
    "print(dt.schema().to_pyarrow())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarrow._parquet.ParquetSchema object at 0x7f87f41e6d00>\n",
      "required group field_id=-1 schema {\n",
      "  optional int64 field_id=-1 datetime (Timestamp(isAdjustedToUTC=false, timeUnit=microseconds, is_from_converted_type=false, force_set_converted_type=false));\n",
      "}\n",
      "\n",
      "<pyarrow._parquet.ParquetSchema object at 0x7f87f408ac40>\n",
      "required group field_id=-1 root {\n",
      "  optional int64 field_id=-1 datetime (Timestamp(isAdjustedToUTC=true, timeUnit=microseconds, is_from_converted_type=false, force_set_converted_type=false));\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "file = \"test/0-64c5f7d8-9779-48bc-af49-aa16881115cf-0.parquet\"\n",
    "\n",
    "metadata = pq.read_metadata(\"test/0-64c5f7d8-9779-48bc-af49-aa16881115cf-0.parquet\")\n",
    "print(metadata.schema)\n",
    "\n",
    "metadata = pq.read_metadata(\"test.parquet\")\n",
    "print(metadata.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    datetime64[us, UTC]\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_parquet(\"test.parquet\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<delta.tables.DeltaTable at 0x7f87c0c29a50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "from delta.tables import DeltaTable\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import lit, to_timestamp, col\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"integer\", IntegerType(), True),\n",
    "    StructField(\"string\", StringType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "])\n",
    "\n",
    "spark = get_spark()\n",
    "\n",
    "path = Path.cwd() / \"schema\"\n",
    "DeltaTable.create(spark).location(str(path)).addColumns(schema).property(\n",
    "    \"delta.minReaderVersion\", \"3\"\n",
    ").property(\"delta.minWriterVersion\", \"7\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema = StructType([\n",
    "    StructField(\"integer\", IntegerType(), True),\n",
    "    StructField(\"string\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "])\n",
    "\n",
    "spark.createDataFrame(\n",
    "    [(4, \"delta\", \"2022-06-29 12:01:19.000\")], schema=schema\n",
    ").withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\")).write.save(\n",
    "    str(path),\n",
    "    mode=\"append\",\n",
    "    format=\"delta\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarrow._parquet.ParquetSchema object at 0x7f87d0862e40>\n",
      "required group field_id=-1 spark_schema {\n",
      "  optional int32 field_id=-1 integer;\n",
      "  optional binary field_id=-1 string (String);\n",
      "  optional int64 field_id=-1 timestamp (Timestamp(isAdjustedToUTC=true, timeUnit=microseconds, is_from_converted_type=false, force_set_converted_type=false));\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = pq.read_metadata(\"schema/part-00000-0d310fe0-1c85-4a03-a464-0501acfd6dde-c000.snappy.parquet\")\n",
    "print(metadata.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "integer: int32\n",
       "string: string\n",
       "timestamp: timestamp[ns]\n",
       "----\n",
       "integer: [[4]]\n",
       "string: [[\"delta\"]]\n",
       "timestamp: [[2022-06-29 10:01:19.000000000]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.read_table(\"schema/part-00023-cda0b9ea-1909-4b03-9e81-a2a87743b903-c000.snappy.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
